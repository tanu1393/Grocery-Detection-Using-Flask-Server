{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K1aZQYPPCz2N",
        "outputId": "20bb88c3-d0d4-43f8-dc22-7d37b70b90b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mish-cuda'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 195 (delta 20), reused 20 (delta 20), pack-reused 169 (from 1)\u001b[K\n",
            "Receiving objects: 100% (195/195), 203.57 KiB | 1.02 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/mish-cuda\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/extension.py:139: UserWarning: Unknown Extension options: 'headers'\n",
            "  warnings.warn(msg)\n",
            "running build\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-cpython-310/mish_cuda\n",
            "copying src/mish_cuda/__init__.py -> build/lib.linux-x86_64-cpython-310/mish_cuda\n",
            "running egg_info\n",
            "creating src/mish_cuda.egg-info\n",
            "writing src/mish_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\n",
            "writing requirements to src/mish_cuda.egg-info/requires.txt\n",
            "writing top-level names to src/mish_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:416: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:426: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'mish_cuda._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/csrc/cpu\n",
            "creating build/temp.linux-x86_64-cpython-310/csrc/cuda\n",
            "x86_64-linux-gnu-g++ -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-cpython-310/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "x86_64-linux-gnu-g++ -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-310/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/mish_cuda/_C.cpython-310-x86_64-linux-gnu.so\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-cpython-310/mish_cuda/__init__.py -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-cpython-310/mish_cuda/_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-310.pyc\n",
            "creating stub loader for mish_cuda/_C.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/mish_cuda-0.0.3-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mish_cuda-0.0.3-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/mish_cuda-0.0.3-py3.10-linux-x86_64.egg\n",
            "Extracting mish_cuda-0.0.3-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding mish-cuda 0.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/mish_cuda-0.0.3-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for mish-cuda==0.0.3\n",
            "Searching for torch==2.5.1+cu121\n",
            "Best match: torch 2.5.1+cu121\n",
            "Adding torch 2.5.1+cu121 to easy-install.pth file\n",
            "detected new path './mish_cuda-0.0.3-py3.10-linux-x86_64.egg'\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchfrtrace script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.13.1\n",
            "Best match: sympy 1.13.1\n",
            "Adding sympy 1.13.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fsspec==2024.10.0\n",
            "Best match: fsspec 2024.10.0\n",
            "Adding fsspec 2024.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for jinja2==3.1.4\n",
            "Best match: jinja2 3.1.4\n",
            "Adding jinja2 3.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.4.2\n",
            "Best match: networkx 3.4.2\n",
            "Adding networkx 3.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for typing-extensions==4.12.2\n",
            "Best match: typing-extensions 4.12.2\n",
            "Adding typing-extensions 4.12.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages/setuptools/_vendor\n",
            "Searching for filelock==3.16.1\n",
            "Best match: filelock 3.16.1\n",
            "Adding filelock 3.16.1 to easy-install.pth file\n",
            "detected new path './setuptools/_vendor'\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==3.0.2\n",
            "Best match: MarkupSafe 3.0.2\n",
            "Adding MarkupSafe 3.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for mish-cuda==0.0.3\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# install mish-cuda if you want to use mish activation\n",
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda\n",
        "!python setup.py build install\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the session after installing mish-cuda : Runtime > Restart session"
      ],
      "metadata": {
        "id": "8iW65cSJF1JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGkZmHyLFjAk",
        "outputId": "ddcaa0de-f116-4c7c-c4c8-ffe385c6564a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip grocery_detect_submission.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdD02Kd7Dbpu",
        "outputId": "bf873f66-dd34-421f-97ee-c898207f9602"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  grocery_detect_submission.zip\n",
            "  inflating: C1_P02_N1_S5_1.JPG      \n",
            "  inflating: C1_P02_N2_S2_1.JPG      \n",
            "  inflating: C1_P03_N2_S2_1.JPG      \n",
            "  inflating: C1_P06_N1_S3_1.JPG      \n",
            "  inflating: C1_P11_N2_S4_3.JPG      \n",
            "  inflating: grocery_detect_client.ipynb  \n",
            "  inflating: grocery_detection_server.ipynb  \n",
            "  inflating: last_yolov4-p5-results_strip.pt  \n",
            " extracting: models/__init__.py      \n",
            "  inflating: models/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/common.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/experimental.cpython-37.pyc  \n",
            "  inflating: models/__pycache__/yolo.cpython-37.pyc  \n",
            "  inflating: models/common.py        \n",
            "  inflating: models/experimental.py  \n",
            "  inflating: models/export.py        \n",
            "  inflating: models/yolo.py          \n",
            "  inflating: models/yolov4-csp.yaml  \n",
            "  inflating: models/yolov4-p5.yaml   \n",
            "  inflating: models/yolov4-p6.yaml   \n",
            "  inflating: models/yolov4-p7.yaml   \n",
            " extracting: utils/__init__.py       \n",
            "  inflating: utils/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: utils/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: utils/__pycache__/general.cpython-37.pyc  \n",
            "  inflating: utils/__pycache__/google_utils.cpython-37.pyc  \n",
            "  inflating: utils/__pycache__/torch_utils.cpython-37.pyc  \n",
            "  inflating: utils/activations.py    \n",
            "  inflating: utils/datasets.py       \n",
            "  inflating: utils/general.py        \n",
            "  inflating: utils/google_utils.py   \n",
            "  inflating: utils/torch_utils.py    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from pathlib import Path\n",
        "import base64\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "import logging\n",
        "\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import (\n",
        "    check_img_size, non_max_suppression, plot_one_box, scale_coords\n",
        ")"
      ],
      "metadata": {
        "id": "fgux8K-GDeGC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Flask application\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Set device for computation (CPU or GPU)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)"
      ],
      "metadata": {
        "id": "QcVs0icVDmtF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO model\n",
        "def load_model():\n",
        "    \"\"\"Load the YOLOv4 model from the specified file.\"\"\"\n",
        "    logging.info(\"Loading the YOLO model.\")\n",
        "    model = torch.load('/content/last_yolov4-p5-results_strip.pt', map_location=device)['model'].float().fuse().eval()\n",
        "    logging.info(\"Model loaded successfully.\")\n",
        "    return model\n",
        "\n",
        "# Perform object detection\n",
        "def detection(img0):\n",
        "    \"\"\"Perform object detection on the given image.\n",
        "\n",
        "    Args:\n",
        "        img0 (numpy.ndarray): The input image for detection.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The processed image with detected objects plotted.\n",
        "    \"\"\"\n",
        "    logging.info(\"Starting detection process.\")\n",
        "    imgsz = 896\n",
        "    imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n",
        "\n",
        "    # Resize and preprocess the image\n",
        "    img = letterbox(img0, new_shape=imgsz)[0]\n",
        "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "    img = np.ascontiguousarray(img)\n",
        "    img = torch.from_numpy(img)\n",
        "    img = img.to(device, non_blocking=True)\n",
        "    img = img.float()\n",
        "    img /= 255.0  # Normalize to 0.0 - 1.0\n",
        "\n",
        "    if img.ndimension() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "\n",
        "    pred = model(img, augment=False)[0]\n",
        "\n",
        "    conf_thres = 0.4\n",
        "    iou_thres = 0.6\n",
        "    pred = non_max_suppression(pred, conf_thres=conf_thres, iou_thres=iou_thres, merge=False)\n",
        "\n",
        "    # Get class names and colors\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
        "\n",
        "    for i, det in enumerate(pred):  # detections per image\n",
        "        gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "        if det is not None and len(det):\n",
        "            # Rescale boxes to original image size\n",
        "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
        "\n",
        "            # Print results\n",
        "            for c in det[:, -1].unique():\n",
        "                n = (det[:, -1] == c).sum()  # detections per class\n",
        "                logging.info(f\"{n} {names[int(c)]} detected.\")\n",
        "\n",
        "            # Draw results on the image\n",
        "            for *xyxy, conf, cls in det:\n",
        "                label = f'{names[int(cls)]}'\n",
        "                plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=2)\n",
        "\n",
        "    logging.info(\"Detection process completed.\")\n",
        "    return img0"
      ],
      "metadata": {
        "id": "yMFnBa79JDDO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the detection endpoint\n",
        "@app.route('/detect', methods=['POST'])\n",
        "def detect():\n",
        "    \"\"\"API endpoint to handle image upload and perform object detection.\"\"\"\n",
        "    if 'image' not in request.files:\n",
        "        logging.error(\"No image file provided in the request.\")\n",
        "        return jsonify({'error': 'No image provided'}), 400\n",
        "\n",
        "    file = request.files['image']\n",
        "    img0 = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "    if img0 is None:\n",
        "        logging.error(\"Invalid image file.\")\n",
        "        return jsonify({'error': 'Invalid image'}), 400\n",
        "\n",
        "    pred = detection(img0)\n",
        "\n",
        "    # Encode the processed image to Base64\n",
        "    _, buffer = cv2.imencode('.jpg', pred)\n",
        "    image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "    logging.info(\"Image processed successfully and encoded to Base64.\")\n",
        "    return jsonify({'image': image_base64})\n",
        "\n",
        "# Define a health check endpoint\n",
        "@app.get('/health')\n",
        "def health():\n",
        "    \"\"\"API endpoint to check service health status.\"\"\"\n",
        "    logging.info(\"Health check endpoint accessed.\")\n",
        "    return jsonify({'message': 'OK'}), 200"
      ],
      "metadata": {
        "id": "-NmFVIA5EWTi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "auth_token = userdata.get('auth_token') #add auth_token secrets of ngrok\n",
        "\n",
        "# Set the authtoken\n",
        "ngrok.set_auth_token(auth_token)\n",
        "\n",
        "# Connect to ngrok\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "\n",
        "# Print the public URL\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "# Run the server\n",
        "model = load_model()\n",
        "app.run(host='0.0.0.0', port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6BXVvnpFfhH",
        "outputId": "c2a32559-4cb2-4245-9253-5eb33a0210da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://147f-34-125-4-238.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4cd4a2795cdf>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('/content/last_yolov4-p5-results_strip.pt', map_location=device)['model'].float().fuse().eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layers... Model Summary: 331 layers, 7.02988e+07 parameters, 6.81919e+07 gradients\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 15:00:07] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 15:02:01] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 15:02:31] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 15:02:56] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 15:03:51] \"POST /detect HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2024 15:05:02] \"POST /detect HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--n-AZHuGwop"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}